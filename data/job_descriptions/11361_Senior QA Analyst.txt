TITLE: Senior QA Analyst

SKILLS: IT Software - QA & Testing

Job Description Â Send me Jobs like this Qualifications & Responsibilities The Senior Quality Assurance Analyst will provide QA services on one or more client projects. Duties and Responsibilities: Depending on the projects supported the Sr. QA Analyst may perform some or all of the below duties: Exercise comprehensive understanding of Software Development Life Cycle and Quality Assurance concepts, metrics and documentation standards Identify and escalate risks and issues to project leadership in accordance with best practices Learns unfamiliar products and technologies with little instruction Receives little instruction on day- to- day work, general instructions on new assignments. Set up meetings as needed with the QA Lead to verify test cases or testing results Setting up and Participating in handoff/ overview meetings/ or testing post- mortems (coming prepared with questions or concerns about any issues seen with the documentation or with the testing effort) Understand Risk Based Approach for Testing QA Documentation Develops, modifies, and/ or executes software Test Plans and Test Strategies and ensure they comply with QA standards and best practices Verifies all formal documentation created, and considers if the testing falls in scope, out of scope, environment dependency, test data dependency, enter and exit criteria, QA and SIT time lines Profile detailed documentation of defects with proper steps to reproduce, screen shots, customer data and any relevant details for proper analysis by the development team Analyzes, contributes to, and/ or writes test standards and procedures Able to define moderate to complex level manual test cases and scenarios Identify and Create a Post Release project document after the release and share with the QA team about the new functionality (for cross training and documenting all new processes and procedures to share with other team members) Create and Maintain Requirements Traceability Matrix QA Testing Review and Analyze FSD/ BRD Provide level of effort estimates for testing tasks as needed (be able to identify a time line for a project and verify if enough time is allotted) . Should be able to identify when a project/ task is falling out of a specific timeline estimate, and will escalate. Analyze requirements to define regression test cases needed Verifying environment is ready for testing effort to begin (install code or scripting when directed by development team) Generate and manage complex levels of test data for test case execution Execute complex Functional test cases/ steps on the new features; confirm that existing functionality and usability have not been negatively altered (from both a black box and gray box perspective) ; update documentation accordingly with results Meet aggressive deadlines and handle multiple and complex workstreams Use independent judgment to plan, prioritize and organize a diversified workload Review system and functional requirements and extract data to use in preparing automated test plans and scripts Integration testing before QA/ SIT to make sure all connectivitys are working Validate data set up/ backend validation is ready for testing to begin. Do a validation of all data set up to see if it is loaded properly per FS and BRD specifications Create Defects when necessary with all appropriate documentation to be able to reproduce the issue and track for closure Work with developers to resolve issue (s) Setup & participate in defect triage meetings Assist Lead QA for Testing Metrics & Reporting Validate all loads are completed and data is properly loaded into the tables (load validation) Run and validate any extract data (compare to the tables loaded with the information in the database) (extract verification) Validate any Reports (compare to the tables loaded with the information in the database) (report verification) Assist Lead QA in defining the Automation Strategy and/ or schedule Review system and functional requirements and extract data to define basic to level automated test cases and scenarios Define easy to moderate level automation test cases and scenarios and ensure it complies with standards Assist lead in providing Automation Reporting / Metrics Assist Lead QA in defining Performance Strategy and/ or schedule Assist Lead QA in defining Performance Load Models Execute performance scripts Assist Lead QA in Performance Reporting Participate in review meetings with key stakeholders to define performance requirements and SLA's Compare backend table information to UI Validate Web Screen set up/ layout/ content with appropriate devices and web browsers Validate any T&C's and FAQ's (compare this to the program requirements and the content provided) on UI Validate Web Service Calls Work with web technologies like HTML, XML and Web services Validate Sonar content zones are set up with appropriate data/ spacing/ font/ colors/ borders, etc. Perform statistics gathering, comparative analysis, and trending Perform Data Quality Analysis (Data hygiene, CDI, etc.) Create a report for source data mapping for capturing data quality and missing data attributes Perform testing through SoapUI or other similar tool Validate API Calls Minimum qualifications: Associate or Bachelors Degree or equivalent experience 5 of years of relevant work experience, including: Strong SQL skills, with ability to write complex queries and be able to script Knowledge of SQL and Relational Database Management Systems, particularly Oracle (WinSQL, PL/ SQL, SQLNav) Knowledge of .net, SOA/ Soap UI, and PUTTY Load Validation Microsoft Project Understanding of or hands- on experience with automated testing tools Analytical and problem solving skills MS Office, including formulas and macros for Microsoft Office components (Excel and Access) Unix (FreeBSD or Linux) Ability to create cron jobs and other basic functions in UNIX QA Methodologies, tools, related techniques, and ability to document & implement Principles of WSDL, XML, and XSD Knowledge of software development lifecycle (SDLC) Understanding of performance engineering processs or hands- on experience with performance testing tools Able to manage the software quality certification function with accuracy and timeliness Leadership skills Experience with any or all of the following is beneficial: Understanding of Direct Marketing Understanding the complete SDLC process Data Management SharePoint Web Browsers (IE, Firefox, Chrome, etc.) TFS MTM Putty Load Validation XML Editors Mobile Technology Testing Data Aggregation Data Warehousing Business Intelligence tools (e.g. Business Objects, Cognos, MicroStrategy) Data Quality Analysis (Data hygiene, CDI, etc.) Report generation (visuals, data input and output) Agile, Waterfall methodologies Data Migration Decision Making Skills Risk Assessment & Management Planning & Follow- through Customer Facing Skills Business Intelligence tools (e.g. Business Objects, Cognos, MicroStrategy) Campaign Management tools (e.g. Unica, Alterian) Marketing concepts Netezza Salary: Not Disclosed by Recruiter Industry: IT-Software / Software Services Functional Area: IT Software - QA & Testing Role Category:Programming & Design Role:Testing Engineer Desired Candidate Profile Education- UG: Any Graduate PG:Any Postgraduate Doctorate:Any Doctorate - Any Specialization, Doctorate Not Required Please refer to the Job description above Company Profile: AllianceData AllianceData Download PPT Photo 1 Â View Contact Details